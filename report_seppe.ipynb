{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report Group 12** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loading packages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69118/2299815974.py:15: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/seppe/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from gymPacMan_new_reward import gymPacMan_parallel_env\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "\n",
    "wandb.login(key = '', relogin = True)\n",
    "team_name = 'RL_PacMan'\n",
    "\n",
    "from util_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 1: All functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Networks**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentQNetwork(nn.Module):\n",
    "    def __init__(self,obs_shape, action_dim,hidden_dim=64):\n",
    "        super(AgentQNetwork, self).__init__()\n",
    "        self.c1 = nn.Conv2d(obs_shape[0], 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.c2 = nn.Conv2d(32, hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.c3 = nn.Conv2d(hidden_dim, 4*hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = torch.relu(self.c1(obs))\n",
    "        x = torch.relu(self.c2(x))\n",
    "        x = torch.relu(self.c3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        q_values = self.fc2(x)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN-LSTM-Q Network\n",
    "\n",
    "\n",
    "class CNNLSTMQNetwork_hidden(nn.Module):\n",
    "    def __init__(self, embed_dim, obs_shape, action_space):\n",
    "        super(CNNLSTMQNetwork_hidden, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Shared encoder for the agent's state\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Conv2d(obs_shape[0], 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Adaptive pooling to handle varying input sizes\n",
    "        )\n",
    "\n",
    "        # Fully connected layer to project encoded state to embed_dim\n",
    "        self.fc = nn.Linear(128 * 1 * 1, embed_dim)\n",
    "\n",
    "        # LSTM layer to model temporal dependencies\n",
    "        self.lstm = nn.LSTM(embed_dim, embed_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        # Final layer to compute Q-values\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Linear(embed_dim, action_space),\n",
    "            nn.SiLU()  # Swish activation\n",
    "        )\n",
    "\n",
    "    def forward(self, state, hidden):\n",
    "        # Process single state using the shared encoder\n",
    "        cnn_features = []\n",
    "        for t in range(5):\n",
    "            \n",
    "            encoded_state = self.shared_encoder(state[:, t, :, :, :])  # Encode the state\n",
    "            encoded_state = encoded_state.view(encoded_state.size(0), -1)  # Flatten to [batch_size, 128 * 1 * 1]\n",
    "            projected_state = self.fc(encoded_state).unsqueeze(1)  # Project to embed_dim and add sequence dimension\n",
    "            cnn_features.append(projected_state)\n",
    "            \n",
    "        cnn_features = torch.cat(cnn_features, dim=1)  # Shape: (batch_size, seq_len, cnn_output_size)\n",
    "        # Apply LSTM to model temporal dependencies\n",
    "        hx, cx = hidden[0, :, :, :], hidden[1, :, :, :]\n",
    "        lstm_out, (hx, cx) = self.lstm(cnn_features, (hx, cx))\n",
    "        hidden_new = torch.stack([hx.detach(), cx.detach()], dim=0)\n",
    "        # Use the output of the LSTM for the final layer\n",
    "        q_values = self.final_layer(lstm_out[:, -1, :])  # Shape: [batch_size, action_space]\n",
    "\n",
    "        return q_values, hidden_new\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.embed_dim),\n",
    "                torch.zeros(1, batch_size, self.embed_dim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixing Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleQMixer(nn.Module):\n",
    "    def __init__(self, n_agents, state_shape):\n",
    "        \"\"\"\n",
    "        Simple QMIX Mixing Network with Convolutional layers.\n",
    "        Args:\n",
    "            n_agents (int): Number of agents.\n",
    "            state_shape (tuple): Shape of the agent-specific input (n_agents, channels, H, W).\n",
    "        \"\"\"\n",
    "        super(SimpleQMixer, self).__init__()\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.state_shape = state_shape\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(state_shape[1], 16, kernel_size=3, stride=1, padding=1),  # state_shape[1] = number of channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        dummy_input = torch.zeros(1, state_shape[1], state_shape[2], state_shape[3])  # [batch_size=1, channels, H, W]\n",
    "        print(f'dummy_input [batch_size=1, channels, H, W] == {dummy_input}')\n",
    "        conv_output_size = self.conv(dummy_input).view(1, -1).size(1)\n",
    "        \n",
    "        # Hypernetwork layers\n",
    "        self.hyper_w = nn.Sequential(\n",
    "            nn.Linear(conv_output_size * n_agents, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_agents)\n",
    "        )\n",
    "        \n",
    "        self.hyper_b = nn.Sequential(\n",
    "            nn.Linear(conv_output_size * n_agents, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, agent_qs, agent_states):\n",
    "        \"\"\"\n",
    "        Forward pass for the mixing network with Convolutional layers.\n",
    "        Args:\n",
    "            agent_qs (torch.Tensor): Tensor of shape [batch_size, n_agents] containing Q-values for each agent.\n",
    "            agent_states (torch.Tensor): Tensor of shape [batch_size, n_agents, channels, H, W].\n",
    "        Returns:\n",
    "            torch.Tensor: Global Q-value of shape [batch_size, 1].\n",
    "        \"\"\"\n",
    "        batch_size, num_agents, channels, height, width = agent_states.shape\n",
    "        \n",
    "        agent_states_r = agent_states.view(batch_size * num_agents, channels, height, width)  # [batch_size * n_agents, channels, H, W]\n",
    "        \n",
    "        conv_features = self.conv(agent_states_r)  # [batch_size * n_agents, conv_channels, H, W]\n",
    "        flattened_features = conv_features.view(batch_size, num_agents, -1)  # [batch_size, n_agents, conv_output_size]\n",
    "        \n",
    "        combined_features = flattened_features.view(batch_size, -1)  # [batch_size, n_agents * conv_output_size]\n",
    "        \n",
    "        w = torch.abs(self.hyper_w(combined_features)).view(batch_size, self.n_agents, 1)\n",
    "        b = self.hyper_b(combined_features).view(batch_size, 1, 1)\n",
    "        \n",
    "        mixed_qs = torch.bmm(agent_qs.unsqueeze(1), w).squeeze(1) + b\n",
    "        \n",
    "        return mixed_qs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionMixer(nn.Module):\n",
    "    def __init__(self, n_agents, state_shape=(2, 8, 10, 20), embed_dim=32, n_heads=4):\n",
    "        super(AttentionMixer, self).__init__()\n",
    "\n",
    "        self.n_agents = n_agents\n",
    "        self.state_shape = state_shape[1:]  # Remove agent dimension\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Shared Conv2D encoder for each agent\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Conv2d(self.state_shape[0], 16, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.SiLU(),  # Swish activation\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.SiLU(),  # Swish activation\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.SiLU(),  # Swish activation\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        # Fully connected layer to project to embed_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, embed_dim),\n",
    "            nn.SiLU()  # Swish activation\n",
    "        )\n",
    "\n",
    "        for m in self.shared_encoder:\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.uniform_(m.weight, 0.9, 1.1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "        for m in self.fc:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight, 0.9, 1.1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "        # Multi-head attention for inter-agent interaction\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, batch_first=True)\n",
    "\n",
    "        # Hypernetwork for mixing weights_enemy and biases\n",
    "        self.hyper_w = nn.Sequential(\n",
    "            nn.Linear(embed_dim * n_agents, embed_dim * embed_dim),\n",
    "            nn.SiLU(),  # Swish activation\n",
    "            nn.Linear(embed_dim * embed_dim, n_agents * embed_dim)\n",
    "        )\n",
    "        self.hyper_b = nn.Sequential(\n",
    "            nn.Linear(embed_dim * n_agents, embed_dim),\n",
    "            nn.SiLU(),  # Swish activation\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "        # Final layer to compute Q_tot\n",
    "        self.final_layer = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 1),\n",
    "            nn.SiLU()  # Swish activation\n",
    "        )\n",
    "\n",
    "        for m in self.hyper_w:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight, 0.9, 1.1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "        for m in self.hyper_b:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight, 0.9, 1.1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "        for m in self.final_layer:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight, 0.9, 1.1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "\n",
    "    def forward(self, agent_qs, states):\n",
    "        batch_size = states.size(0)\n",
    "\n",
    "        # Process each agent's state individually using the shared encoder\n",
    "        agent_features = []\n",
    "        for i in range(self.n_agents):\n",
    "            agent_state = states[:, i, :, :, :]  # Shape: [batch_size, 8, 10, 20]\n",
    "            encoded_state = self.shared_encoder(agent_state)  # Encode individual agent\n",
    "            encoded_state = encoded_state.view(batch_size, -1)  # Flatten to [batch_size, 128]\n",
    "            projected_state = self.fc(encoded_state)  # Project to embed_dim\n",
    "            agent_features.append(projected_state)\n",
    "\n",
    "        # Stack agent features: Shape [batch_size, n_agents, embed_dim]\n",
    "        agent_features = torch.stack(agent_features, dim=1)\n",
    "\n",
    "        # Apply attention to model inter-agent interaction\n",
    "        attention_out, _ = self.attention(agent_features, agent_features, agent_features)\n",
    "\n",
    "        # Flatten attention output for hypernetwork\n",
    "        attention_out_flat = attention_out.reshape(batch_size, -1)  # Shape: [batch_size, n_agents * embed_dim]\n",
    "\n",
    "        # Compute hypernetwork weights and biases\n",
    "        hyper_w = F.softplus(self.hyper_w(attention_out_flat).view(batch_size, self.n_agents, self.embed_dim))\n",
    "        hyper_b = self.hyper_b(attention_out_flat).view(batch_size, self.embed_dim)\n",
    "\n",
    "        # Combine agent Q-values with weights and biases\n",
    "        agent_qs = agent_qs.view(batch_size, self.n_agents, 1)  # Shape: [batch_size, n_agents, 1]\n",
    "        weighted_qs = torch.bmm(agent_qs.transpose(1, 2), hyper_w).squeeze(1) + hyper_b\n",
    "\n",
    "        # Final projection to Q_tot\n",
    "        q_tot = self.final_layer(weighted_qs).unsqueeze(1)\n",
    "        return q_tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loss calculations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_td_loss_iql(agent_q_networks, target_q_networks, batch, weights=None, gamma=0.99, lambda_=0.1):\n",
    "    \"\"\"\n",
    "    Computes the TD loss for QMix training using the Huber loss.\n",
    "\n",
    "    Args:\n",
    "        agent_q_networks (list): List of Q-networks for each agent.\n",
    "        mixing_network (SimpleQMixer): The mixing network to compute global Q-values.\n",
    "        target_q_networks (list): List of target Q-networks for each agent.\n",
    "        batch (tuple): A batch of experiences (states, actions, rewards, next_states, dones).\n",
    "        weights (torch.Tensor): Importance sampling weights (optional).\n",
    "        gamma (float): Discount factor for future rewards.\n",
    "        lambda_ (float): Regularization factor for stability.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Total loss for training.\n",
    "    \"\"\"\n",
    "    states, actions, rewards, next_states, dones = batch\n",
    "\n",
    "    # Convert to tensors and move to device\n",
    "    states = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "    actions = torch.tensor(actions, dtype=torch.long).to(device)\n",
    "    rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "    next_states = torch.tensor(next_states, dtype=torch.float32).to(device)\n",
    "    dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Current Q-values for each agent\n",
    "    agent_q_values = []\n",
    "    for agent_index, q_net in enumerate(agent_q_networks):\n",
    "        q_vals = q_net(states[:, agent_index, :, :, :])  # Get Q-values for each agent\n",
    "        agent_q_values.append(\n",
    "            q_vals.gather(dim=1, index=actions[:, agent_index].unsqueeze(1)))  # Select Q-value for taken action\n",
    "    agent_q_values = torch.cat(agent_q_values, dim=1)  # Shape: (batch_size, n_agents)\n",
    "\n",
    "    # Target Q-values using Double DQN\n",
    "    with torch.no_grad():\n",
    "        # Get actions from current Q-networks\n",
    "        next_agent_q_values = []\n",
    "        for agent_index, (q_net, target_net) in enumerate(zip(agent_q_networks, target_q_networks)):\n",
    "            next_q_vals = q_net(next_states[:, agent_index, :, :, :])  # Get Q-values from current network\n",
    "            max_next_actions = next_q_vals.argmax(dim=1, keepdim=True)  # Greedy actions\n",
    "            target_q_vals = target_net(next_states[:, agent_index, :, :, :])  # Get Q-values from target network\\\n",
    "            max_next_q_vals = target_q_vals.gather(1, max_next_actions)\n",
    "            done_mask = dones[:, 0, 0].unsqueeze(1)\n",
    "            filtered_target_q_vals = max_next_q_vals * (1 - done_mask)\n",
    "\n",
    "            next_agent_q_values.append(filtered_target_q_vals)  # Use target Q-values for selected actions\n",
    "        next_agent_q_values = torch.cat(next_agent_q_values, dim=1)  # Shape: (batch_size, n_agents)\n",
    "\n",
    "    # Independent Q-learning target for each agent (all members of the blue team receive the same reward)\n",
    "    target_q = rewards[:, 0, 0].unsqueeze(1) + gamma * next_agent_q_values\n",
    "\n",
    "    # Compute Huber loss, try also with MSE loss\n",
    "    loss_fn = torch.nn.HuberLoss()\n",
    "\n",
    "    loss_agent1 = loss_fn(agent_q_values[:, 0], target_q[:, 0])\n",
    "    loss_agent2 = loss_fn(agent_q_values[:, 1], target_q[:, 1])\n",
    "\n",
    "    return loss_agent1, loss_agent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Q-Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Q-Learning for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Replay buffers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size=10000):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        experiences = random.sample(self.buffer, batch_size)\n",
    "\n",
    "        # Restructure the batch into separate arrays for states, actions, rewards, next_states, and dones\n",
    "        states = np.array([exp[0].cpu().numpy() for exp in experiences], dtype=np.float32)\n",
    "        actions = np.array([exp[1] for exp in experiences], dtype=np.int64)\n",
    "        rewards = np.array([exp[2] for exp in experiences])\n",
    "        next_states = np.array([exp[3].cpu().numpy() for exp in experiences])\n",
    "        dones = np.array([exp[4] for exp in experiences])\n",
    "\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer for sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer_sequence:\n",
    "    def __init__(self, buffer_size=10000, sequence_length=5):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        sequences = []\n",
    "        for _ in range(batch_size):\n",
    "            start_index = random.randint(0, len(self.buffer) - self.sequence_length)\n",
    "            sequence = [self.buffer[i] for i in range(start_index, start_index + self.sequence_length)]\n",
    "            sequences.append(sequence)\n",
    "        \n",
    "        # Transpose the sequences to get batches of each component\n",
    "        \n",
    "        states = torch.stack([torch.stack([torch.stack(seq[0]).to(device) for seq in sequence]) for sequence in sequences], dim=0)\n",
    "        actions = torch.stack([torch.stack([torch.tensor(seq[1]).to(device) for seq in sequence]) for sequence in sequences], dim=0)\n",
    "        rewards = torch.stack([torch.stack([torch.tensor(seq[2]).to(device) for seq in sequence]) for sequence in sequences], dim=0)\n",
    "        next_states = torch.stack([torch.stack([torch.stack(seq[3]).to(device) for seq in sequence]) for sequence in sequences], dim=0)\n",
    "        terminations = torch.stack([torch.stack([torch.tensor(seq[4], dtype=torch.int).to(device) for seq in sequence]) for sequence in sequences], dim=2)\n",
    "        hidden_states = torch.cat([sequence[-1][5] for sequence in sequences], dim = -2).to(device)\n",
    "        next_hidden_states = torch.cat([sequence[-1][6] for sequence in sequences], dim = -2).to(device)\n",
    "        \n",
    "        return (states, actions, rewards, next_states, terminations, hidden_states, next_hidden_states)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Also see 'util_functions.py' !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted epsilon-greedy action function\n",
    "def epsilon_greedy_action(agent_q_network, state, epsilon, legal_actions, exploring = True):\n",
    "    \n",
    "    if random.random() < epsilon and exploring:\n",
    "        # Explore: take a random action\n",
    "        action = random.choice(legal_actions)\n",
    "    else:\n",
    "        state = state.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        q_values = agent_q_network(state)\n",
    "        q_values = q_values.cpu().detach().numpy()\n",
    "        action = np.random.choice(np.flatnonzero(q_values == q_values.max()))\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def update_target_network(agent_q_networks, target_q_networks):\n",
    "    for target, source in zip(target_q_networks, agent_q_networks):\n",
    "        target.load_state_dict(source.state_dict())\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_weights(start_weights, end_weights, factor):\n",
    "    return [(1 - factor) * start + factor * end for start, end in zip(start_weights, end_weights)]\n",
    "\n",
    "def get_dynamic_weights(episode, n_episodes):\n",
    "    # Define the initial weights for the beginning, middle, and end\n",
    "    weights_beginning = [1, 0, 0, 0, 0, 0]\n",
    "    weights_middle = [0, 0.33, 0.34, 0.33, 0, 0]\n",
    "    weights_end = [0, 0, 0, 0, 0.5, 0.5]\n",
    "\n",
    "    # Calculate the transition points\n",
    "    transition1 = n_episodes // 3\n",
    "    transition2 = 2 * n_episodes // 3\n",
    "\n",
    "    # Adjust weights based on the current episode\n",
    "    if episode < transition1:\n",
    "        factor = episode / transition1\n",
    "        return interpolate_weights(weights_beginning, weights_middle, factor)\n",
    "    elif episode < transition2:\n",
    "        factor = (episode - transition1) / (transition2 - transition1)\n",
    "        return interpolate_weights(weights_middle, weights_end, factor)\n",
    "    else:\n",
    "        factor = (episode - transition2) / (n_episodes - transition2)\n",
    "        return interpolate_weights(weights_middle, weights_end, factor)\n",
    "    \n",
    "\n",
    "import os\n",
    "\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 2: Training loops** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import layout\n",
    "from distanceCalculator import Distancer\n",
    "\n",
    "def train_iql(env, name_experiment, agent_q_networks, target_q_networks, replay_buffer, train_p, learn_p, random_enemy=False, schedule=False, later_exploration = False):\n",
    "    \n",
    "    optimizer = optim.Adam([param for net in agent_q_networks for param in net.parameters()], lr=learn_p.lr_agent)\n",
    "    #mixing_optimizer = optim.Adam(mixing_network.parameters(), lr=learn_p.lr_mixing)\n",
    "    if schedule:\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=learn_p.gamma)\n",
    "        #scheduler_mix = torch.optim.lr.scheduler.ExponentialLR(mixing_optimizer, gamma=learn_p.learn_gamma)\n",
    "   \n",
    "    n_episodes = train_p.n_episodes\n",
    "    batch_size = train_p.batch_size\n",
    "    gamma = train_p.gamma\n",
    "    epsilon = train_p.epsilon  # Initial exploration probability\n",
    "    epsilon_min = train_p.epsilon_min\n",
    "    epsilon_decay = train_p.epsilon_decay\n",
    "    target_update_frequency = train_p.target_update_frequency\n",
    "\n",
    "    \n",
    "    legal_actions = [0, 1, 2, 3, 4]\n",
    "    agent_indexes = [1, 3]\n",
    "    episode_rewards = []\n",
    "    win_rates = []\n",
    "    enemieName = env.enemieName\n",
    "    if random_enemy:\n",
    "        enemylist = ['randomTeam.py', 'baselineTeam.py', 'heuristicTeam.py', 'approxQTeam.py', 'MCTSTeam.py', 'AstarTeam.py']\n",
    "        weights_enemy = get_dynamic_weights(0, n_episodes)\n",
    "        enemieName = np.random.choice(enemylist, p=weights_enemy)\n",
    "\n",
    "    create_folder_if_not_exists(name_experiment)\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        steps_counter = 0\n",
    "        print(f\"enemy: {enemieName}\")\n",
    "\n",
    "        done = {agent_id: False for agent_id in agent_indexes}\n",
    "        if random_enemy:\n",
    "            weights_enemy = get_dynamic_weights(episode, n_episodes)\n",
    "            enemieName = np.random.choice(enemylist, p=weights_enemy)\n",
    "        env.reset(enemieName=enemieName)\n",
    "        blue_player1_reward = 0\n",
    "        blue_player2_reward = 0\n",
    "        score = 0\n",
    "        if later_exploration:\n",
    "            exploring = False\n",
    "        else:\n",
    "            exploring = True\n",
    "        while not all(done.values()):\n",
    "            if later_exploration and steps_counter > 10:\n",
    "                exploring = True\n",
    "            actions = [-1 for _, _ in enumerate(env.agents)]\n",
    "            states = []\n",
    "            for i, agent_index in enumerate(agent_indexes):\n",
    "                obs_agent = env.get_Observation(agent_index)\n",
    "                state = torch.tensor(obs_agent, dtype=torch.float32).to(device)\n",
    "                states.append(state)\n",
    "                action = epsilon_greedy_action(agent_q_networks[i], state, epsilon, legal_actions, exploring)\n",
    "                actions[agent_index] = action\n",
    "\n",
    "\n",
    "\n",
    "            next_states, rewards, terminations, info = env.step(actions)\n",
    "            score -= info[\"score_change\"]\n",
    "            done = {key: value for key, value in terminations.items() if key in agent_indexes}\n",
    "            blue_player1_reward += rewards[1]\n",
    "            blue_player2_reward += rewards[3]\n",
    "\n",
    "            next_states_converted = []\n",
    "            rewards_converted = []\n",
    "            terminations_converted = []\n",
    "            actions_converted = []\n",
    "\n",
    "            for index in agent_indexes:\n",
    "                next_states_converted.append(list(next_states.values())[index])\n",
    "                rewards_converted.append(rewards[index])\n",
    "                terminations_converted.append(terminations[index])\n",
    "                actions_converted.append(actions[index])\n",
    "                car = env.game.state.getAgentState(index).numCarrying\n",
    "                print(car)\n",
    "\n",
    "            next_states_converted = torch.stack(next_states_converted)\n",
    "            states_converted = torch.stack(states)\n",
    "            rewards_converted = [rewards_converted]\n",
    "            terminations_converted = [terminations_converted]\n",
    "            replay_buffer.add(\n",
    "                (states_converted, actions_converted, rewards_converted, next_states_converted, terminations_converted))\n",
    "\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                loss1, loss2 = compute_td_loss_iql(agent_q_networks, target_q_networks, batch,\n",
    "                                               gamma=gamma)\n",
    "                wandb.log({\"loss1\": loss1})\n",
    "                wandb.log({\"loss2\": loss2})\n",
    "\n",
    "                # Zero gradients for all optimizers\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Backpropagate once for all losses\n",
    "                loss1.backward(retain_graph=True)\n",
    "                loss2.backward()\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                if schedule:\n",
    "                    scheduler.step()\n",
    "                    wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "            steps_counter += 1\n",
    "        wandb.log({\"epsilon\": epsilon})\n",
    "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "        wandb.log({\"blue_player1_reward\": blue_player1_reward})\n",
    "        wandb.log({\"blue_player2_reward\": blue_player2_reward})\n",
    "        wandb.log({\"episode\": episode})\n",
    "        wandb.log({'score': score})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (episode + 1) % target_update_frequency == 0:\n",
    "            update_target_network(agent_q_networks, target_q_networks)\n",
    "        \n",
    "        if (episode) % target_update_frequency == 0:\n",
    "            torch.save(agent_q_networks[0].state_dict(),f'{name_experiment}/agent1_{episode+1}.pth')\n",
    "            torch.save(agent_q_networks[1].state_dict(),f'{name_experiment}/agent3_{episode+1}.pth')\n",
    "         # Log rewards and win rates\n",
    "        episode_rewards.append(blue_player1_reward+blue_player2_reward)\n",
    "        print(blue_player1_reward)\n",
    "        print(blue_player2_reward)\n",
    "        print(f\"Episode reward: {blue_player1_reward+blue_player2_reward}\")\n",
    "\n",
    "        if np.sum(env.game.state.getBlueFood().data) == 0:\n",
    "            win_rates.append(1)\n",
    "        else:\n",
    "            win_rates.append(0)\n",
    "\n",
    "        if (episode + 1) % 10 == 0:\n",
    "            avg_reward = np.mean(episode_rewards[-10:])\n",
    "            avg_win_rate = np.mean(win_rates[-10:])\n",
    "            print(f\"Episode {episode + 1}/{n_episodes}, Average Reward: {avg_reward:.2f}, Win Rate: {avg_win_rate:.2f}\")\n",
    "\n",
    "    # Plot rewards and win rates\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episode_rewards, label=\"Average Reward\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Average Reward per Episode\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    smoothed_win_rates = np.convolve(win_rates, np.ones(10)/10, mode='valid') if len(win_rates) > 10 else win_rates\n",
    "    plt.plot(smoothed_win_rates, label=\"Win Rate (Smoothed)\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Win Rate\")\n",
    "    plt.title(\"Win Rate Over Episodes\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_qmix(env, name_experiment, agent_q_networks, target_q_networks, mixing_networks, replay_buffer, train_p, learn_p, random_enemy=False, schedule=False, later_exploration = False):\n",
    "    \n",
    "    optimizer = optim.Adam([param for net in agent_q_networks for param in net.parameters()], lr=learn_p.lr_agent)\n",
    "    #mixing_optimizer = optim.Adam(mixing_network.parameters(), lr=learn_p.lr_mixing)\n",
    "    if schedule:\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=learn_p.gamma)\n",
    "        #scheduler_mix = torch.optim.lr.scheduler.ExponentialLR(mixing_optimizer, gamma=learn_p.learn_gamma)\n",
    "   \n",
    "    n_episodes = train_p.n_episodes\n",
    "    batch_size = train_p.batch_size\n",
    "    gamma = train_p.gamma\n",
    "    epsilon = train_p.epsilon  # Initial exploration probability\n",
    "    epsilon_min = train_p.epsilon_min\n",
    "    epsilon_decay = train_p.epsilon_decay\n",
    "    target_update_frequency = train_p.target_update_frequency\n",
    "\n",
    "    \n",
    "    \n",
    "    legal_actions = [0, 1, 2, 3, 4]\n",
    "    agent_indexes = [1, 3]\n",
    "    episode_rewards = []\n",
    "    win_rates = []\n",
    "    enemieName = env.enemieName\n",
    "    if random_enemy:\n",
    "        enemylist = ['randomTeam.py', 'baselineTeam.py', 'heuristicTeam.py', 'approxQTeam.py', 'MCTSTeam.py', 'AstarTeam.py']\n",
    "        weights_enemy = get_dynamic_weights(0, n_episodes)\n",
    "        enemieName = np.random.choice(enemylist, p=weights_enemy)\n",
    "\n",
    "    create_folder_if_not_exists(name_experiment)\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        steps_counter = 0\n",
    "        print(f\"enemy: {enemieName}\")\n",
    "\n",
    "        done = {agent_id: False for agent_id in agent_indexes}\n",
    "        if random_enemy:\n",
    "            weights_enemy = get_dynamic_weights(episode, n_episodes)\n",
    "            enemieName = np.random.choice(enemylist, p=weights_enemy)\n",
    "        env.reset(enemieName=enemieName)\n",
    "        blue_player1_reward = 0\n",
    "        blue_player2_reward = 0\n",
    "        score = 0\n",
    "        if later_exploration:\n",
    "            exploring = False\n",
    "        else:\n",
    "            exploring = True\n",
    "        while not all(done.values()):\n",
    "            if later_exploration and steps_counter > 10:\n",
    "                exploring = True\n",
    "            actions = [-1 for _, _ in enumerate(env.agents)]\n",
    "            states = []\n",
    "            for i, agent_index in enumerate(agent_indexes):\n",
    "                obs_agent = env.get_Observation(agent_index)\n",
    "                state = torch.tensor(obs_agent, dtype=torch.float32).to(device)\n",
    "                states.append(state)\n",
    "                action = epsilon_greedy_action(agent_q_networks[i], state, epsilon, legal_actions, exploring)\n",
    "                actions[agent_index] = action\n",
    "\n",
    "\n",
    "\n",
    "            next_states, rewards, terminations, info = env.step(actions)\n",
    "            score -= info[\"score_change\"]\n",
    "            done = {key: value for key, value in terminations.items() if key in agent_indexes}\n",
    "            blue_player1_reward += rewards[1]\n",
    "            blue_player2_reward += rewards[3]\n",
    "\n",
    "            next_states_converted = []\n",
    "            rewards_converted = []\n",
    "            terminations_converted = []\n",
    "            actions_converted = []\n",
    "\n",
    "            for index in agent_indexes:\n",
    "                next_states_converted.append(list(next_states.values())[index])\n",
    "                rewards_converted.append(rewards[index])\n",
    "                terminations_converted.append(terminations[index])\n",
    "                actions_converted.append(actions[index])\n",
    "\n",
    "            next_states_converted = torch.stack(next_states_converted)\n",
    "            states_converted = torch.stack(states)\n",
    "            rewards_converted = [rewards_converted]\n",
    "            terminations_converted = [terminations_converted]\n",
    "            replay_buffer.add(\n",
    "                (states_converted, actions_converted, rewards_converted, next_states_converted, terminations_converted))\n",
    "\n",
    "            if replay_buffer.size() >= batch_size:\n",
    "                batch = replay_buffer.sample(batch_size)\n",
    "                loss1, loss2 = compute_td_loss_iql(agent_q_networks, target_q_networks, batch,\n",
    "                                               gamma=gamma)\n",
    "                wandb.log({\"loss1\": loss1})\n",
    "                wandb.log({\"loss2\": loss2})\n",
    "\n",
    "                # Zero gradients for all optimizers\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Backpropagate once for all losses\n",
    "                loss1.backward(retain_graph=True)\n",
    "                loss2.backward()\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                if schedule:\n",
    "                    scheduler.step()\n",
    "                    wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "            steps_counter += 1\n",
    "        wandb.log({\"epsilon\": epsilon})\n",
    "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "        wandb.log({\"blue_player1_reward\": blue_player1_reward})\n",
    "        wandb.log({\"blue_player2_reward\": blue_player2_reward})\n",
    "        wandb.log({\"episode\": episode})\n",
    "        wandb.log({'score': score})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (episode + 1) % target_update_frequency == 0:\n",
    "            update_target_network(agent_q_networks, target_q_networks)\n",
    "        \n",
    "        if (episode) % target_update_frequency == 0:\n",
    "            torch.save(agent_q_networks[0].state_dict(),f'{name_experiment}/agent1_{episode+1}.pth')\n",
    "            torch.save(agent_q_networks[1].state_dict(),f'{name_experiment}/agent3_{episode+1}.pth')\n",
    "         # Log rewards and win rates\n",
    "        episode_rewards.append(blue_player1_reward+blue_player2_reward)\n",
    "        print(blue_player1_reward)\n",
    "        print(blue_player2_reward)\n",
    "        print(f\"Episode reward: {blue_player1_reward+blue_player2_reward}\")\n",
    "\n",
    "        if np.sum(env.game.state.getBlueFood().data) == 0:\n",
    "            win_rates.append(1)\n",
    "        else:\n",
    "            win_rates.append(0)\n",
    "\n",
    "        if (episode + 1) % 10 == 0:\n",
    "            avg_reward = np.mean(episode_rewards[-10:])\n",
    "            avg_win_rate = np.mean(win_rates[-10:])\n",
    "            print(f\"Episode {episode + 1}/{n_episodes}, Average Reward: {avg_reward:.2f}, Win Rate: {avg_win_rate:.2f}\")\n",
    "\n",
    "    # Plot rewards and win rates\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episode_rewards, label=\"Average Reward\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Average Reward per Episode\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    smoothed_win_rates = np.convolve(win_rates, np.ones(10)/10, mode='valid') if len(win_rates) > 10 else win_rates\n",
    "    plt.plot(smoothed_win_rates, label=\"Win Rate (Smoothed)\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Win Rate\")\n",
    "    plt.title(\"Win Rate Over Episodes\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qmix_LSTM():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_PPO():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Section 3: Testing and conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing IQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 300 steps with random enemy on win.lay with fixed lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class train_param:\n",
    "    n_episodes: int = 200\n",
    "    batch_size: int = 32\n",
    "    gamma: float = 0.95\n",
    "    epsilon: float = 0.75\n",
    "    epsilon_min: float = 0.1\n",
    "    epsilon_decay: float = 0.995\n",
    "    target_update_frequency: int = 20\n",
    "\n",
    "@dataclass\n",
    "class learn_param:\n",
    "    lr_mix: float = 0.0001\n",
    "    lr_agent: float = 0.0001\n",
    "    gamma: float = 0.99995\n",
    "\n",
    "#TODO: specific net_param for each network architecture\n",
    "@dataclass\n",
    "class net_param_CNN:\n",
    "    hidden_dim: int = 64\n",
    "    \n",
    "\n",
    "train_p_iql = train_param()\n",
    "learn_p_iql = learn_param()\n",
    "net_p_iql = net_param_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout from file\n",
      "Loading Team: /home/seppe/RL/RL_MARL_QMIX//agents/randomTeam.py\n",
      "Arguments: {}\n",
      "Blue team starts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/seppe-wuyts3-universiteit-gent/uncategorized/runs/__20241211_005615?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f15bb74cb50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gymPacMan_parallel_env(display=True, layout_file=\"layouts/tinyCapture.lay\", length=100, enemieName='randomTeam.py', defenceReward=True)\n",
    "name_experiment =''\n",
    "wandb.init(project=\"\", id = f\"{name_experiment}__{datetime.now().strftime('%Y%m%d_%H%M%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 2\n",
    "action_dim = 5\n",
    "\n",
    "obs_individual_agent = env.get_Observation(0)\n",
    "obs_shape = obs_individual_agent.shape\n",
    "\n",
    "agent_q_networks = [AgentQNetwork(obs_shape, action_dim, hidden_dim=net_p_iql.hidden_dim).to(device) for _ in range(n_agents)]\n",
    "target_q_networks = [AgentQNetwork(obs_shape, action_dim, hidden_dim=net_p_iql.hidden_dim).to(device) for _ in range(n_agents)]\n",
    "update_target_network(agent_q_networks, target_q_networks)\n",
    "\n",
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enemy: randomTeam.py\n",
      "Loading Team: /home/seppe/RL/RL_MARL_QMIX//agents/randomTeam.py\n",
      "Arguments: {}\n",
      "Red team starts\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69118/4278391711.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(obs_agent, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 3)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 4)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 3)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 3)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 3)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 3)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 4)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 4)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 5)\n",
      "10\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(17, 5)\n",
      "9\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 5)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(16, 5)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 5)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 4)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(15, 4)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 3)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 3)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(15, 3)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(15, 4)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(15, 5)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(14, 5)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(14, 5)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(13, 5)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(13, 4)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(13, 3)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1.2900000000000007\n",
      "1.2900000000000007\n",
      "Episode reward: 2.5800000000000014\n",
      "enemy: randomTeam.py\n",
      "Loading Team: /home/seppe/RL/RL_MARL_QMIX//agents/randomTeam.py\n",
      "Arguments: {}\n",
      "Blue team starts\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 3)\n",
      "8\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 3)\n",
      "7\n",
      "1.300000000000001\n",
      "1.300000000000001\n",
      "Episode reward: 2.600000000000002\n",
      "enemy: randomTeam.py\n",
      "Loading Team: /home/seppe/RL/RL_MARL_QMIX//agents/randomTeam.py\n",
      "Arguments: {}\n",
      "Red team starts\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 3)\n",
      "7\n",
      "1.1400000000000008\n",
      "1.1400000000000008\n",
      "Episode reward: 2.2800000000000016\n",
      "enemy: randomTeam.py\n",
      "Loading Team: /home/seppe/RL/RL_MARL_QMIX//agents/randomTeam.py\n",
      "Arguments: {}\n",
      "Blue team starts\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(16, 1)\n",
      "4\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 1)\n",
      "4\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 1)\n",
      "5\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 2)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(17, 1)\n",
      "5\n",
      "3\n",
      "(13, 1)\n",
      "(18, 3)\n",
      "7\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 3)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 3)\n",
      "7\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(18, 3)\n",
      "7\n",
      "1\n",
      "(12, 1)\n",
      "(18, 2)\n",
      "7\n",
      "3\n",
      "(13, 1)\n",
      "(18, 3)\n",
      "7\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 3)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(17, 3)\n",
      "6\n",
      "1\n",
      "(12, 1)\n",
      "(18, 1)\n",
      "6\n",
      "3\n",
      "(13, 1)\n",
      "(16, 3)\n",
      "5\n",
      "1.2400000000000007\n",
      "1.2400000000000007\n",
      "Episode reward: 2.4800000000000013\n",
      "enemy: randomTeam.py\n",
      "Loading Team: /home/seppe/RL/RL_MARL_QMIX//agents/randomTeam.py\n",
      "Arguments: {}\n",
      "Blue team starts\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(16, 1)\n",
      "3\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(15, 1)\n",
      "3\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(12, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "0\n",
      "3\n",
      "(13, 1)\n",
      "(13, 1)\n",
      "0\n",
      "1\n",
      "(12, 1)\n",
      "(13, 1)\n",
      "1\n",
      "3\n",
      "(13, 1)\n",
      "(14, 1)\n",
      "1\n",
      "1\n",
      "(12, 1)\n",
      "(14, 1)\n",
      "2\n",
      "3\n",
      "(13, 1)\n",
      "(15, 1)\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m name_experiment \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIQL_CNN_tiny_new_rea\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m train_iql(env, name_experiment, agent_q_networks, target_q_networks, replay_buffer, train_p_iql, learn_p_iql)\n",
      "Cell \u001b[0;32mIn[28], line 61\u001b[0m, in \u001b[0;36mtrain_iql\u001b[0;34m(env, name_experiment, agent_q_networks, target_q_networks, replay_buffer, train_p, learn_p, random_enemy, schedule, later_exploration)\u001b[0m\n\u001b[1;32m     59\u001b[0m     state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(obs_agent, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m     states\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[0;32m---> 61\u001b[0m     action \u001b[38;5;241m=\u001b[39m epsilon_greedy_action(agent_q_networks[i], state, epsilon, legal_actions, exploring)\n\u001b[1;32m     62\u001b[0m     actions[agent_index] \u001b[38;5;241m=\u001b[39m action\n\u001b[1;32m     66\u001b[0m next_states, rewards, terminations, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mepsilon_greedy_action\u001b[0;34m(agent_q_network, state, epsilon, legal_actions, exploring)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m agent_q_network(state)\n\u001b[1;32m     10\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m q_values\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39mflatnonzero(q_values \u001b[38;5;241m==\u001b[39m q_values\u001b[38;5;241m.\u001b[39mmax()))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mAgentQNetwork.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc1(obs))\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc2(x))\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc3(x))\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_pool(x)\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/fx/traceback.py:72\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(traceback\u001b[38;5;241m.\u001b[39mextract_stack()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/traceback.py:231\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 231\u001b[0m stack \u001b[38;5;241m=\u001b[39m StackSummary\u001b[38;5;241m.\u001b[39mextract(walk_stack(f), limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[1;32m    232\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/traceback.py:393\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass\u001b[38;5;241m.\u001b[39m_extract_from_extended_frame_gen(\n\u001b[1;32m    394\u001b[0m     extended_frame_gen(), limit\u001b[38;5;241m=\u001b[39mlimit, lookup_lines\u001b[38;5;241m=\u001b[39mlookup_lines,\n\u001b[1;32m    395\u001b[0m     capture_locals\u001b[38;5;241m=\u001b[39mcapture_locals)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/traceback.py:421\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    418\u001b[0m filename \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_filename\n\u001b[1;32m    419\u001b[0m name \u001b[38;5;241m=\u001b[39m co\u001b[38;5;241m.\u001b[39mco_name\n\u001b[0;32m--> 421\u001b[0m fnames\u001b[38;5;241m.\u001b[39madd(filename)\n\u001b[1;32m    422\u001b[0m linecache\u001b[38;5;241m.\u001b[39mlazycache(filename, f\u001b[38;5;241m.\u001b[39mf_globals)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Must defer line lookups until we have called checkcache.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "name_experiment ='IQL_CNN_tiny_new_rea'\n",
    "\n",
    "train_iql(env, name_experiment, agent_q_networks, target_q_networks, replay_buffer, train_p_iql, learn_p_iql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQL on tiny with random enemy with scheduled learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer()\n",
    "name_experiment ='IQL_CNN_tiny'\n",
    "team_name = 'RL_PacMan'\n",
    "\n",
    "env = gymPacMan_parallel_env(display=True, layout_file=\"layouts/tinyCapture.lay\", length=300, enemieName='randomTeam.py', defenceReward=True)\n",
    "wandb.init(entity = team_name, project=\"PacManCapture\", id = f\"{name_experiment}__{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "\n",
    "train_iql(env, name_experiment, agent_q_networks, target_q_networks, replay_buffer, train_p_iql, learn_p_iql)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the list of enemies\n",
    "enemies = ['randomTeam.py', 'baselineTeam.py', 'heuristicTeam.py', 'approxQTeam.py', 'MCTSTeam.py', 'AstarTeam.py']\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {enemy: {'wins': 0, 'losses': 0, 'draws': 0} for enemy in enemies}\n",
    "\n",
    "# Number of games to play against each enemy\n",
    "num_games = 10\n",
    "\n",
    "# Function to evaluate the agent against an enemy\n",
    "def evaluate_agent(env, enemy_name, num_games):\n",
    "    wins, losses, draws = 0, 0, 0\n",
    "    for _ in range(num_games):\n",
    "        env.reset(enemieName=enemy_name)\n",
    "        done = False\n",
    "        while not done:\n",
    "            actions = [-1 for _, _ in enumerate(env.agents)]\n",
    "            states = []\n",
    "            for i, agent_index in enumerate([1,3]):\n",
    "                obs_agent = env.get_Observation(agent_index)\n",
    "                state = torch.tensor(obs_agent, dtype=torch.float32).to(device)\n",
    "                states.append(state)\n",
    "                state = state.unsqueeze(0).to(device)  # Add batch dimension\n",
    "                q_values = agent_q_networks[i](state)\n",
    "                q_values = q_values.cpu().detach().numpy()\n",
    "                action = np.random.choice(np.flatnonzero(q_values == q_values.max()))\n",
    "                actions[agent_index] = action\n",
    "            next_state, reward, done, info = env.step(actions)\n",
    "            if done:\n",
    "                if info['result'] == 'win':\n",
    "                    wins += 1\n",
    "                elif info['result'] == 'loss':\n",
    "                    losses += 1\n",
    "                else:\n",
    "                    draws += 1\n",
    "    return wins, losses, draws\n",
    "\n",
    "# Evaluate the agent against each enemy\n",
    "for enemy in enemies:\n",
    "    env = gymPacMan_parallel_env(display=False, layout_file=\"layouts/smallCapture.lay\", length=200, enemieName=enemy, defenceReward=True)\n",
    "    wins, losses, draws = evaluate_agent(env, enemy, num_games)\n",
    "    results[enemy]['wins'] = wins\n",
    "    results[enemy]['losses'] = losses\n",
    "    results[enemy]['draws'] = draws\n",
    "\n",
    "# Convert results to a DataFrame for better display\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing idea's**\n",
    "\n",
    "- experience buffer\n",
    "- only exploration after first 10 steps\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
