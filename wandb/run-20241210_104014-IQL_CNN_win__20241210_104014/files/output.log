Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
C:\Users\josse\AppData\Local\Temp\ipykernel_14928\558125621.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  state = torch.tensor(obs_agent, dtype=torch.float32).to(device)
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
C:\Users\josse\AppData\Local\Temp\ipykernel_14928\558125621.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  state = torch.tensor(obs_agent, dtype=torch.float32).to(device)
4.409999999999986
4.409999999999986
Episode reward: 8.819999999999972
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
4.609999999999988
4.609999999999988
Episode reward: 9.219999999999976
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
