Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
torch.Size([8, 20, 20])
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
torch.Size([8, 10, 11])
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
torch.Size([8, 11, 14])
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
torch.Size([8, 7, 20])
0
Loaded random layout
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
torch.Size([8, 20, 20])
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
torch.Size([8, 9, 10])
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
torch.Size([8, 11, 17])
Loaded layout from file
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX\venv\Lib\site-packages\torch\nn\modules\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
[4, 8, 11, 14]
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
C:\Users\josse\AppData\Local\Temp\ipykernel_5580\152869123.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  state = torch.tensor(obs_agent, dtype=torch.float32).to(device)
2.0000000000000013
2.0000000000000013
Episode reward: 4.000000000000003
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
1.360000000000001
1.360000000000001
Episode reward: 2.720000000000002
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
1.5100000000000011
1.5100000000000011
Episode reward: 3.0200000000000022
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
1.320000000000001
1.320000000000001
Episode reward: 2.640000000000002
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
1.2200000000000009
1.2200000000000009
Episode reward: 2.4400000000000017
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
1.1800000000000008
1.1800000000000008
Episode reward: 2.3600000000000017
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
1.0400000000000007
1.0400000000000007
Episode reward: 2.0800000000000014
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
0.8600000000000005
0.8600000000000005
Episode reward: 1.720000000000001
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
0.7000000000000005
0.7000000000000005
Episode reward: 1.400000000000001
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
0.6200000000000003
0.6200000000000003
Episode reward: 1.2400000000000007
Episode 10/1000, Average Reward: 2.36, Win Rate: 0.00
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
0.4100000000000002
0.4100000000000002
Episode reward: 0.8200000000000004
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
0.5200000000000002
0.5200000000000002
Episode reward: 1.0400000000000005
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Blue team starts
0.3200000000000001
0.3200000000000001
Episode reward: 0.6400000000000002
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
0.47000000000000025
0.47000000000000025
Episode reward: 0.9400000000000005
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
0.4300000000000002
0.4300000000000002
Episode reward: 0.8600000000000004
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
0.4200000000000002
0.4200000000000002
Episode reward: 0.8400000000000004
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
0.26000000000000006
0.26000000000000006
Episode reward: 0.5200000000000001
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
0.2700000000000001
0.2700000000000001
Episode reward: 0.5400000000000001
enemy: randomTeam.py
Loading Team: c:\Users\josse\OneDrive\Documenten\creditcontract\RL\RL_MARL_QMIX//agents/randomTeam.py
Arguments: {}
Red team starts
